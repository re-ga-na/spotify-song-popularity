{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'exp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b01563c4e8ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\\\Users\\\\rcalde1\\\\Python_Columbia\\\\Final_project'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'exp'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import statsmodels.formula.api as sm\n",
    "import statsmodels.regression.linear_model as lm\n",
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\suhaibkiani\\\\desktop\\\\Final_project')\n",
    "import exp\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# plotting modules\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"features_45k.csv\"\n",
    "tds1 = pd.read_csv(file)\n",
    "tds1 = tds1[['Artist', 'Track', 'followers','instrumentalness','popularity','acousticness', 'danceability', 'duration_ms', 'energy', 'key', 'liveness', 'loudness', 'mode',\n",
    "       'speechiness', 'tempo', 'time_signature', 'valence']]\n",
    "tds1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#to perform the train test split of the data, the train test split function is imported from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "#the given problem is a classificaton problem. Hence linear regression is used for ML algorithm\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combined Dataset\n",
    "dfcombine = tds1\n",
    "#dfcombine = dfcombine.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#Target Dataset\n",
    "dfy = pd.DataFrame(tds1[\"popularity\"])\n",
    "\n",
    "#all the independant variables/predictors are named as dfx\n",
    "dfx = dfcombine.drop(columns=['Artist', 'Track','popularity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfx.shape)\n",
    "print(dfy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rid of NaN, infinity or a value too large for dtype('float64').\n",
    "\n",
    "np.where(dfx.values >= np.finfo(np.float64).max)\n",
    "np.isnan(dfx.values.any())\n",
    "dfx.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "np.where(dfy.values >= np.finfo(np.float64).max)\n",
    "np.isnan(dfy.values.any())\n",
    "dfy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "dfx.reset_index(inplace=True, drop=True)\n",
    "dfy.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(dfx.shape)\n",
    "print(dfy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the percentage of the split is taken as 30%. SO the percentage of training is 70%\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfx, dfy, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression \n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the target is predicted for the test dataset\n",
    "predictions = model.predict(X_test)\n",
    "#the accuracy of the prediction is found to be.... \n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle A: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pickle Package\n",
    "import pickle\n",
    "# Save the Modle to file in the current working directory\n",
    "Pkl_Filename = \"Pickle_45_Model.pkl\"  \n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(model, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Model back from file\n",
    "with open(Pkl_Filename, 'rb') as file:  \n",
    "    Pickled_LR_Model = pickle.load(file)\n",
    "Pickled_LR_Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Reloaded Model to \n",
    "# Calculate the accuracy score and predict target values\n",
    "# Calculate the Score \n",
    "score = Pickled_LR_Model.score(X_test, y_test)  \n",
    "# Print the Score\n",
    "print(\"Test score: {0:.2f} \".format(score))  \n",
    "# Predict the Labels using the reloaded Model\n",
    "Y_predict = Pickled_LR_Model.predict(X_test)  \n",
    "Y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv (r'C:\\Users\\Suhaib Kiani\\Desktop\\X_test.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_csv (r'C:\\Users\\Suhaib Kiani\\Desktop\\y_test.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle B: Random_Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, roc_auc_score \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = tds1\n",
    "print(dataframe.shape)\n",
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.loc[dataframe['popularity'] < 60, 'popularity'] = 0 \n",
    "dataframe.loc[dataframe['popularity'] >= 60, 'popularity'] = 1\n",
    "dataframe['popularity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_x = ['followers','instrumentalness','acousticness', 'danceability', 'duration_ms', 'energy', 'key', 'liveness', 'loudness', 'mode',\n",
    "       'speechiness', 'tempo', 'time_signature', 'valence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next we define 80% of the dataframe for training and 20% of the dataframe for testing.\n",
    "training = dataframe.sample(frac = 0.8,random_state = 420)\n",
    "X_train = training[features_x]\n",
    "y_train = training['popularity']\n",
    "X_test = dataframe.drop(training.index)[features_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We add a validation dataset using train_test_split.\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_Model = RandomForestClassifier()\n",
    "RFC_Model.fit(X_train, y_train)\n",
    "RFC_Predict = RFC_Model.predict(X_valid)\n",
    "RFC_Accuracy = accuracy_score(y_valid, RFC_Predict)\n",
    "print(\"Accuracy: \" + str(RFC_Accuracy))\n",
    "\n",
    "RFC_AUC = roc_auc_score(y_valid, RFC_Predict) \n",
    "print(\"AUC: \" + str(RFC_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pickle Package\n",
    "import pickle\n",
    "# Save the Modle to file in the current working directory\n",
    "Pkl_Filename2 = \"Pickle_45_Model2.pkl\"  \n",
    "with open(Pkl_Filename2, 'wb') as file2:  \n",
    "    pickle.dump(RFC_Model, file2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Model back from file\n",
    "with open(Pkl_Filename2, 'rb') as file2:  \n",
    "    Pickled_LR_Model2 = pickle.load(file2)\n",
    "Pickled_LR_Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_Model2 = Pickled_LR_Model2\n",
    "RFC_Model2.fit(X_train, y_train)\n",
    "RFC_Predict2 = RFC_Model2.predict(X_valid)\n",
    "RFC_Accuracy2 = accuracy_score(y_valid, RFC_Predict2)\n",
    "print(\"Accuracy: \" + str(RFC_Accuracy2))\n",
    "RFC_AUC2 = roc_auc_score(y_valid, RFC_Predict2) \n",
    "print(\"AUC: \" + str(RFC_AUC2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid.to_csv (r'C:\\Users\\Suhaib Kiani\\Desktop\\X_valid.csv', index = False, header=True)\n",
    "y_valid.to_csv (r'C:\\Users\\Suhaib Kiani\\Desktop\\y_valid.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
